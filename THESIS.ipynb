{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d7421c2-2672-443f-ad68-821a166dc352",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a70891a-1878-4a44-9cdd-161fde948b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# Built-in / Utilities\n",
    "# =======================\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =======================\n",
    "# Core Libraries\n",
    "# =======================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# =======================\n",
    "# Visualization\n",
    "# =======================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# =======================\n",
    "# Image Processing\n",
    "# =======================\n",
    "from PIL import Image, ImageStat\n",
    "\n",
    "# =======================\n",
    "# Scikit-learn\n",
    "# =======================\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error\n",
    ")\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# =======================\n",
    "# Statistics\n",
    "# =======================\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# =======================\n",
    "# TensorFlow / Keras\n",
    "# =======================\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import (\n",
    "    ImageDataGenerator,\n",
    "    load_img,\n",
    "    img_to_array\n",
    ")\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# =======================\n",
    "# PyTorch\n",
    "# =======================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# =======================\n",
    "# Progress Bar\n",
    "# =======================\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm as tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90627bbe-4204-497e-a976-98afe71cb1c8",
   "metadata": {},
   "source": [
    "### PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b075bf17-e98e-4b09-ab44-15a14ddb1870",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### FER-2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c7e2c3-a792-4b24-85ae-d512ad0b2d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = 'fer2013/train'\n",
    "path_test = 'fer2013/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef9e858-e812-4fde-b19b-3cb7846b2da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(os.listdir(path_train))\n",
    "class_map = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "num_classes = len(class_names)\n",
    "img_size = (224, 224, 3)\n",
    "\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f255c8c-788b-4547-87dc-78cb16c3f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "  images_path = []\n",
    "  labels = []\n",
    "\n",
    "  for folder in os.listdir(path):\n",
    "    label = folder\n",
    "    for file in tqdm(os.listdir(os.path.join(path, folder)), desc = f\"Loading {folder}\"):\n",
    "      img_path = os.path.join(path, folder, file)\n",
    "      images_path.append(img_path)\n",
    "      labels.append(label)\n",
    "\n",
    "  return images_path, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2195a82-3da9-4ed4-8335-d633ef46898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataset into data frame\n",
    "images, labels = load_dataset(path_train)\n",
    "train = pd.DataFrame({'images': list(images), 'labels': labels})\n",
    "\n",
    "# shuffling the training dataset\n",
    "train = train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b2b571-b8ce-4617-80d5-42d3c6d3baba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels = load_dataset(path_test)\n",
    "test = pd.DataFrame({'images': list(test_images), 'labels': test_labels})\n",
    "\n",
    "test = test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82053c2b-8124-4916-837f-e10260b87251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_raw_image(img_path):\n",
    "    img = load_img(img_path)\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Raw Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "show_raw_image(train['images'].iloc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d584f37c-42ae-4ca2-9d9c-e7a2a2bb13cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "def extract_features(imgs):\n",
    "  features = []\n",
    "  for img in tqdm(imgs, desc = \"Extracting features\"):\n",
    "    img = load_img(img, color_mode='rgb', target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "\n",
    "    features.append(img)\n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b91e70-9998-40e8-a8d3-688c875356ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = extract_features(train['images'])\n",
    "test_features = extract_features(test['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2027bd7b-addf-452e-9722-d4d278c1afbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_resized_image(img_path):\n",
    "    img = load_img(img_path, color_mode='rgb', target_size=(224, 224))\n",
    "    img_array = img_to_array(img).astype(\"uint8\")\n",
    "\n",
    "    plt.imshow(img_array)\n",
    "    plt.title(\"Resized Image (224x224)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "show_resized_image(train['images'].iloc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836b186a-8ed3-4f0a-a261-b1ec33312348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert and Normalize\n",
    "## Neural nets converge faster if pixel values are scaled to [0,1] (or standardized).\n",
    "train_features = np.array(train_features) / 255.0\n",
    "test_features = np.array(test_features) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76abc62e-b305-472e-87f8-2ef9b55baa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_normalized_image(img_path):\n",
    "    img = load_img(img_path, color_mode='rgb', target_size=(224, 224))\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "\n",
    "    plt.imshow(img_array)\n",
    "    plt.title(\"Normalized Image [0,1]\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    print(\"Before normalization:\", img_to_array(load_img(train['images'].iloc[5])).min(),\n",
    "      img_to_array(load_img(train['images'].iloc[5])).max())\n",
    "\n",
    "    print(\"After normalization:\", img_array.min(), img_array.max())\n",
    "\n",
    "show_normalized_image(train['images'].iloc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d5b460-e7ec-4a9e-8e8a-353de420d5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "datagen.fit(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe42aa70-4db6-411f-8f98-d692d2e7014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_augmentation(img_path, n=5):\n",
    "    img = load_img(img_path, target_size=(224, 224))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, 0)\n",
    "\n",
    "    aug_iter = datagen.flow(img_array, batch_size=1)\n",
    "\n",
    "    plt.figure(figsize=(15,3))\n",
    "    for i in range(n):\n",
    "        augmented = next(aug_iter)[0].astype(\"uint8\")\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.imshow(augmented)\n",
    "        plt.title(f\"Augmented {i+1}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "show_augmentation(train['images'].iloc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e2690c-aa43-4b91-9526-8626fc931657",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(x=train['labels'])\n",
    "plt.title(\"Class Distribution Before Balancing\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fa7739-6002-41c9-af82-9d235a37c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing Dataset\n",
    "# Convert labels to numerical format\n",
    "y_train = train['labels'].map(class_map).values\n",
    "y_test = test['labels'].map(class_map).values\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3787d5-171a-4b71-8f88-837ab36ee0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['labels'].map(class_map).values\n",
    "classes = np.unique(y_train)\n",
    "\n",
    "inv_class_map = {v: k for k, v in class_map.items()}\n",
    "class_names = [inv_class_map[c] for c in classes]\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "bars = plt.bar(class_names, class_weights)\n",
    "plt.title(\"Class Weights Distribution\")\n",
    "plt.xlabel(\"Emotion Class\")\n",
    "plt.ylabel(\"Weight\")\n",
    "plt.xticks(rotation=45)\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width()/2,\n",
    "        height,\n",
    "        f\"{height:.2f}\",\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontsize=9\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc48eb5a-a6fb-4db0-bd6e-b5288d646e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train shape :\", train_features.shape)\n",
    "print(\"Test shape  :\", test_features.shape)\n",
    "print(\"Train label :\", y_train.shape)\n",
    "print(\"Test label  :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d9813d-da01-4942-be93-c0da7ec4437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_img = img_to_array(load_img(train['images'].iloc[0]))\n",
    "norm_img = raw_img / 255.0\n",
    "\n",
    "print(\"Mean pixel before normalization:\", raw_img.mean())\n",
    "print(\"Mean pixel after normalization :\", norm_img.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b041a2-8909-4153-9cde-0cc8cd74f876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "np.savez_compressed(\n",
    "    \"fer2013_processed_final.npz\",\n",
    "    X_train=train_features,\n",
    "    y_train=y_train,\n",
    "    X_test=test_features,\n",
    "    y_test=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4571d33-1aa4-41c8-8108-d10204896fcf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### SCUT-FBP5500 V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37f6506-dabc-42ed-b7a7-8a18e9fe35c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scut_label_path= r'C:\\Users\\felic\\OneDrive - Bina Nusantara\\THESISSS\\DATASET\\SCUT-FBP5500\\labels.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0ac405-7336-41b5-b399-51dc6fc6f65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scut_df = pd.read_csv(scut_label_path, sep=' ', header=None, names=['filename', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d43308-89b0-4990-b2e9-a79474a52c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "scut_df['filename'] = scut_df['filename'].str.strip()\n",
    "\n",
    "# Ambil daftar file yang benar-benar ada di folder\n",
    "scut_image_folder = r'C:\\Users\\felic\\OneDrive - Bina Nusantara\\THESISSS\\DATASET\\SCUT-FBP5500\\Images\\Images'\n",
    "available_images = set(os.listdir(scut_image_folder))\n",
    "\n",
    "# Filter label hanya untuk file yang tersedia\n",
    "scut_df_filtered = scut_df[scut_df['filename'].isin(available_images)]\n",
    "\n",
    "print(f\"Ada {len(scut_df_filtered)} data yang cocok antara label dan file gambar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e48ec27-5acf-4739-a3f1-a176af5cc482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction untuk SCUT-FBP5500 (tanpa brightness filter)\n",
    "def extract_scut_features(df, image_folder):\n",
    "    features = []\n",
    "    labels = []\n",
    "    failed = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Extracting SCUT features\"):\n",
    "        img_path = os.path.join(image_folder, row['filename'].strip())\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "            # Resize ke 224x224\n",
    "            img = img.resize((224, 224))\n",
    "            img_array = np.array(img)\n",
    "            features.append(img_array)\n",
    "            labels.append(row['score'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "            failed.append(row['filename'])\n",
    "    return np.array(features), np.array(labels), failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4c0aa2-c11c-4307-a2fe-8f3b835d0e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scut_features, scut_labels, failed_files = extract_scut_features(scut_df_filtered, scut_image_folder)\n",
    "print(\"File yang gagal dimuat:\", failed_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a002cb6f-55bb-4609-8a7e-85aed6a9df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ekstraksi fitur\n",
    "scut_features, scut_labels = extract_scut_features(scut_df_filtered, scut_image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d19d7ec-c300-4244-b1e8-1b95aabeb1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(scut_features)} gambar berhasil dimuat.\")\n",
    "print(f\"Shape gambar: {scut_features.shape}\")\n",
    "print(f\"Contoh label: {scut_labels[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d215279-b3a8-4c8d-a3bb-059aa33fedd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dan Normalize\n",
    "scut_features = scut_features / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c4758-067d-4d4c-8e21-e023b99b387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 80/10/10 stratified\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    scut_features, scut_labels, test_size=0.2, stratify=np.round(scut_labels)\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=np.round(y_temp)\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4055da-2628-4b1b-a515-843fd9f24291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation (ringan untuk SCUT)\n",
    "scut_datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=10,          # rotasi kecil\n",
    "    brightness_range=[0.8, 1.2] # penyesuaian brightness\n",
    ")\n",
    "\n",
    "scut_datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6760a050-c2b1-40d7-a0a0-946769ef27f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save hasil preprocess ke file .npz\n",
    "np.savez_compressed(\n",
    "    \"scutfbp5500_processed_final.npz\",\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test\n",
    ")\n",
    "print(\"SCUT-FBP5500 dataset berhasil disimpan ke 'scutfbp5500_processed_final.npz'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ccce70-3059-4527-9e5d-8908abbb0272",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "for idx, row in tqdm(df_filtered.iterrows(), total=len(df_filtered)):\n",
    "    img_path = os.path.join(image_folder, row['filename'])\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = img.resize((224, 224))  # Ukuran bisa disesuaikan dengan model\n",
    "        img_array = np.array(img) / 255.0  # Normalisasi ke [0, 1]\n",
    "        images.append(img_array)\n",
    "        labels.append(row['score'])  # Sesuaikan dengan nama kolom label\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {img_path}: {e}\")\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(f\"{len(images)} gambar berhasil dimuat.\")\n",
    "print(f\"Shape gambar: {images.shape}\")\n",
    "print(f\"Contoh label: {labels[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c31e06-d34b-47ed-b272-f3ff50f2db88",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d98acc-eb40-428c-bcba-af4965b6cae1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Single-Task Beauty Score Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16bb89d-e0b1-45d3-bd01-3362668c8e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCUTPreprocessedDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for pre-normalized SCUT-FBP5500 data\n",
    "    Data is already normalized to [0, 1] and sized to 224x224\n",
    "    \"\"\"\n",
    "    def __init__(self, npz_file, X_key, y_key, augment=False):\n",
    "        print(f\"Loading {X_key} and {y_key} from {npz_file}...\")\n",
    "        \n",
    "        # Load data directly (it's small enough)\n",
    "        data = np.load(npz_file)\n",
    "        self.images = data[X_key]  # Shape: (N, 224, 224, 3), range [0, 1]\n",
    "        self.scores = data[y_key].astype(np.float32)  # Shape: (N,)\n",
    "        \n",
    "        print(f\"✓ Loaded {len(self.scores)} samples\")\n",
    "        print(f\"✓ Image shape: {self.images.shape}\")\n",
    "        print(f\"✓ Score range: {self.scores.min():.2f} to {self.scores.max():.2f}\")\n",
    "        \n",
    "        self.augment = augment\n",
    "        \n",
    "        # Define augmentation transforms (if needed)\n",
    "        if augment:\n",
    "            self.aug_transform = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "                transforms.RandomRotation(degrees=5),\n",
    "            ])\n",
    "        \n",
    "        # Always convert to tensor and apply ImageNet normalization\n",
    "        self.to_tensor = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.scores)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get image (already normalized to [0,1])\n",
    "        img_array = self.images[idx]  # Shape: (224, 224, 3), range [0, 1]\n",
    "        score = float(self.scores[idx])\n",
    "        \n",
    "        # Convert to uint8 for PIL Image (denormalize to [0, 255])\n",
    "        img_array = (img_array * 255).astype(np.uint8)\n",
    "        \n",
    "        # Convert to PIL Image\n",
    "        img = Image.fromarray(img_array, mode='RGB')\n",
    "        \n",
    "        # Apply augmentation if training\n",
    "        if self.augment:\n",
    "            img = self.aug_transform(img)\n",
    "        \n",
    "        # Convert to tensor and normalize\n",
    "        img = self.to_tensor(img)\n",
    "        \n",
    "        return img, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8666c8-1c57-403c-ade1-42327f14626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"LOADING SCUT-FBP5500 DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "npz_file = 'scutfbp5500_processed_final.npz'\n",
    "\n",
    "# Create datasets \n",
    "train_dataset = SCUTPreprocessedDataset(npz_file, 'X_train', 'y_train', augment=True)\n",
    "val_dataset = SCUTPreprocessedDataset(npz_file, 'X_val', 'y_val', augment=False)\n",
    "test_dataset = SCUTPreprocessedDataset(npz_file, 'X_test', 'y_test', augment=False)\n",
    "\n",
    "print(f\"\\n✓ Train: {len(train_dataset)} samples\")\n",
    "print(f\"✓ Val:   {len(val_dataset)} samples\")\n",
    "print(f\"✓ Test:  {len(test_dataset)} samples\")\n",
    "\n",
    "batch_size = 32  # Adjust based on your GPU memory\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                         num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                       num_workers=0, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                        num_workers=0, pin_memory=True)\n",
    "\n",
    "print(f\"\\n✓ DataLoaders created (batch_size={batch_size})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045b3811-8c73-4411-9bd8-e4d89bf9783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "print(\"Loading EfficientNet-B0 for facial attractiveness regression...\")\n",
    "\n",
    "# Load pretrained EfficientNet-B0\n",
    "# Gunakan weights parameter untuk PyTorch versi terbaru\n",
    "try:\n",
    "    # PyTorch >= 1.13 (gunakan weights)\n",
    "    from torchvision.models import EfficientNet_B0_Weights\n",
    "    model = models.efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "except:\n",
    "    # PyTorch < 1.13 (gunakan pretrained)\n",
    "    model = models.efficientnet_b0(pretrained=True)\n",
    "\n",
    "# Modify classifier for regression\n",
    "# EfficientNet-B0 memiliki 1280 features di classifier\n",
    "num_features = model.classifier[1].in_features\n",
    "\n",
    "# Replace classifier dengan regression head\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.5, inplace=True),\n",
    "    nn.Linear(num_features, 512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(128, 1)  # Single output for regression\n",
    ")\n",
    "\n",
    "# Freeze early layers for transfer learning\n",
    "# EfficientNet menggunakan 'features' untuk backbone\n",
    "for name, param in model.named_parameters():\n",
    "    # Hanya train classifier dan beberapa block terakhir\n",
    "    if 'classifier' not in name and 'features.7' not in name and 'features.6' not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "print(\"✓ EfficientNet-B0 modified for regression\")\n",
    "print(f\"✓ Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "print(f\"✓ Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1833b522-8262-4791-bd96-e6983495e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MSE for regression\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizer with different learning rates untuk berbagai layer\n",
    "optimizer = optim.AdamW([\n",
    "    {'params': model.classifier.parameters(), 'lr': 1e-3},\n",
    "    {'params': model.features[7].parameters(), 'lr': 1e-4},\n",
    "    {'params': model.features[6].parameters(), 'lr': 5e-5},\n",
    "], weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5,\n",
    "    min_lr=1e-7\n",
    ")\n",
    "\n",
    "# Mixed precision training\n",
    "scaler = torch.cuda.amp.GradScaler() if device.type == \"cuda\" else None\n",
    "\n",
    "# Training parameters\n",
    "epochs = 100\n",
    "patience = 15\n",
    "min_delta = 0.001\n",
    "best_val_mae = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "history = {\n",
    "    'train_loss': [], 'train_mae': [], 'train_rmse': [],\n",
    "    'val_loss': [], 'val_mae': [], 'val_rmse': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59e09cf-28df-47de-90f7-7df2a650134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SANITY CHECK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "model.eval()\n",
    "test_imgs, test_scores = next(iter(train_loader))\n",
    "print(f\"✓ Batch shape: {test_imgs.shape}\")\n",
    "print(f\"✓ Batch min/max: {test_imgs.min():.4f}, {test_imgs.max():.4f}\")\n",
    "print(f\"✓ Scores: {test_scores[:5].tolist()}\")\n",
    "print(f\"✓ Scores range: {test_scores.min():.2f} to {test_scores.max():.2f}\")\n",
    "\n",
    "test_imgs = test_imgs.to(device)\n",
    "with torch.no_grad():\n",
    "    predictions = model(test_imgs).squeeze()\n",
    "\n",
    "print(f\"✓ Predictions shape: {predictions.shape}\")\n",
    "print(f\"✓ Predictions sample: {predictions[:5].tolist()}\")\n",
    "print(f\"✓ Predictions range: {predictions.min():.2f} to {predictions.max():.2f}\")\n",
    "print(\"\\n✓ Model is working correctly!\")\n",
    "print(\"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6231196-1179-482e-8b81-9905c7830431",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STARTING TRAINING WITH EFFICIENTNET-B0\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # ============ TRAINING PHASE ============\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_preds, train_targets = [], []\n",
    "    \n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1:3d}/{epochs} [Train]\", ncols=100)\n",
    "    \n",
    "    for imgs, scores in train_bar:\n",
    "        imgs = imgs.to(device)\n",
    "        scores = scores.to(device).float().unsqueeze(1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if scaler:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, scores)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, scores)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        train_preds.extend(outputs.detach().cpu().numpy())\n",
    "        train_targets.extend(scores.cpu().numpy())\n",
    "        \n",
    "        train_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    train_preds = np.array(train_preds).flatten()\n",
    "    train_targets = np.array(train_targets).flatten()\n",
    "    train_mae = mean_absolute_error(train_targets, train_preds)\n",
    "    train_rmse = np.sqrt(mean_squared_error(train_targets, train_preds))\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    \n",
    "    # ============ VALIDATION PHASE ============\n",
    "    model.eval()\n",
    "    val_preds, val_targets = [], []\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1:3d}/{epochs} [Val]  \", ncols=100)\n",
    "        \n",
    "        for imgs, scores in val_bar:\n",
    "            imgs = imgs.to(device)\n",
    "            scores = scores.to(device).float().unsqueeze(1)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, scores)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            val_preds.extend(outputs.cpu().numpy())\n",
    "            val_targets.extend(scores.cpu().numpy())\n",
    "            \n",
    "            val_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    val_preds = np.array(val_preds).flatten()\n",
    "    val_targets = np.array(val_targets).flatten()\n",
    "    val_mae = mean_absolute_error(val_targets, val_preds)\n",
    "    val_rmse = np.sqrt(mean_squared_error(val_targets, val_preds))\n",
    "    val_loss /= len(val_loader)\n",
    "    \n",
    "    # Pearson correlation\n",
    "    val_corr = np.corrcoef(val_targets, val_preds)[0, 1]\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    \n",
    "    # Store history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_mae'].append(train_mae)\n",
    "    history['train_rmse'].append(train_rmse)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_mae'].append(val_mae)\n",
    "    history['val_rmse'].append(val_rmse)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Epoch {epoch+1:3d}/{epochs} | Time: {epoch_time/60:.1f}min\")\n",
    "    print(f\"{'-'*70}\")\n",
    "    print(f\"Train | Loss: {train_loss:.4f} | MAE: {train_mae:.4f} | RMSE: {train_rmse:.4f}\")\n",
    "    print(f\"Val   | Loss: {val_loss:.4f} | MAE: {val_mae:.4f} | RMSE: {val_rmse:.4f} | Corr: {val_corr:.4f}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_mae)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Learning Rate: {current_lr:.2e}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_mae < best_val_mae - min_delta:\n",
    "        best_val_mae = val_mae\n",
    "        patience_counter = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_mae': val_mae,\n",
    "            'val_rmse': val_rmse,\n",
    "            'val_corr': val_corr,\n",
    "            'history': history\n",
    "        }, \"best_efficientnet_scut_model.pth\")\n",
    "        print(f\" Model saved! Best Val MAE: {val_mae:.4f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\" No improvement ({patience_counter}/{patience})\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\n Early stopping at epoch {epoch+1}\")\n",
    "            print(f\"Best Val MAE: {best_val_mae:.4f}\")\n",
    "            break\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443001b1-c384-4749-9fc5-2026b3cfbca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPlotting training history...\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss (MSE)')\n",
    "axes[0].set_title('Training & Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# MAE\n",
    "axes[1].plot(history['train_mae'], label='Train MAE', linewidth=2)\n",
    "axes[1].plot(history['val_mae'], label='Val MAE', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].set_title('Mean Absolute Error')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# RMSE\n",
    "axes[2].plot(history['train_rmse'], label='Train RMSE', linewidth=2)\n",
    "axes[2].plot(history['val_rmse'], label='Val RMSE', linewidth=2)\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('RMSE')\n",
    "axes[2].set_title('Root Mean Squared Error')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('efficientnet_training_history.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Training history saved as 'efficientnet_training_history.png'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b648106b-7f4c-453e-a063-3aee580a1591",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL EVALUATION ON TEST SET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "checkpoint = torch.load(\"best_efficientnet_scut_model.pth\", weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"\\n✓ Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"✓ Best Val MAE: {checkpoint['val_mae']:.4f}\")\n",
    "print(f\"✓ Best Val RMSE: {checkpoint['val_rmse']:.4f}\")\n",
    "print(f\"✓ Best Val Correlation: {checkpoint['val_corr']:.4f}\\n\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_preds, test_targets = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, scores in tqdm(test_loader, desc=\"Testing\"):\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model(imgs)\n",
    "        test_preds.extend(outputs.cpu().numpy())\n",
    "        test_targets.extend(scores.numpy())\n",
    "\n",
    "test_preds = np.array(test_preds).flatten()\n",
    "test_targets = np.array(test_targets).flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "test_mae = mean_absolute_error(test_targets, test_preds)\n",
    "test_rmse = np.sqrt(mean_squared_error(test_targets, test_preds))\n",
    "test_mse = mean_squared_error(test_targets, test_preds)\n",
    "test_corr = np.corrcoef(test_targets, test_preds)[0, 1]\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(\"TEST SET RESULTS:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"MAE:         {test_mae:.4f}\")\n",
    "print(f\"RMSE:        {test_rmse:.4f}\")\n",
    "print(f\"MSE:         {test_mse:.4f}\")\n",
    "print(f\"Correlation: {test_corr:.4f}\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6dfad5-65dc-42ab-ba23-b74b4ecc4aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Scatter plot: Predictions vs Ground Truth\n",
    "axes[0, 0].scatter(test_targets, test_preds, alpha=0.6, s=30, edgecolors='black', linewidth=0.5)\n",
    "axes[0, 0].plot([test_targets.min(), test_targets.max()], \n",
    "                [test_targets.min(), test_targets.max()], \n",
    "                'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[0, 0].set_xlabel('True Attractiveness Score', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Predicted Score', fontsize=12)\n",
    "axes[0, 0].set_title(f'Predictions vs Ground Truth\\nMAE: {test_mae:.4f} | Corr: {test_corr:.4f}', \n",
    "                     fontsize=13, fontweight='bold')\n",
    "axes[0, 0].legend(fontsize=10)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Error distribution\n",
    "errors = test_preds - test_targets\n",
    "axes[0, 1].hist(errors, bins=30, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "axes[0, 1].axvline(0, color='red', linestyle='--', linewidth=2, label='Zero Error')\n",
    "axes[0, 1].set_xlabel('Prediction Error', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0, 1].set_title(f'Error Distribution\\nMean: {errors.mean():.4f} | Std: {errors.std():.4f}', \n",
    "                     fontsize=13, fontweight='bold')\n",
    "axes[0, 1].legend(fontsize=10)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Residual plot\n",
    "axes[1, 0].scatter(test_targets, errors, alpha=0.6, s=30, edgecolors='black', linewidth=0.5)\n",
    "axes[1, 0].axhline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1, 0].set_xlabel('True Score', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Residual (Predicted - True)', fontsize=12)\n",
    "axes[1, 0].set_title('Residual Plot', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Score distribution comparison\n",
    "axes[1, 1].hist(test_targets, bins=20, alpha=0.5, label='True Scores', \n",
    "                edgecolor='black', color='green')\n",
    "axes[1, 1].hist(test_preds, bins=20, alpha=0.5, label='Predicted Scores', \n",
    "                edgecolor='black', color='orange')\n",
    "axes[1, 1].set_xlabel('Attractiveness Score', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1, 1].set_title('Score Distribution Comparison', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].legend(fontsize=10)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('efficientnet_scut_test_results.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Test results saved as 'efficientnet_scut_test_results.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0240d5c-21bc-4740-96e5-8f23d83c46eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Multi-Task Learning Beauty Score and Emotion Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b74f1c0-7b74-4276-a6b6-82d337ae3590",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetMTLModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Task Learning with EfficientNet-B0 backbone\n",
    "    Architecture matches thesis description exactly:\n",
    "    - Feature Extractor: EfficientNet-B0 (pretrained)\n",
    "    - Pooling Layer: Adaptive pooling for dimensionality reduction\n",
    "    - Two branches: Regression (beauty) + Classification (emotion)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_emotions=7):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Feature Extractor: EfficientNet-B0 (pretrained on ImageNet)\n",
    "        self.backbone = models.efficientnet_b0(pretrained=True)\n",
    "        in_features = self.backbone.classifier[1].in_features  # 1280\n",
    "        self.backbone.classifier = nn.Identity()  # Remove original classifier\n",
    "        \n",
    "        print(f\"✓ Feature Extractor: EfficientNet-B0 (pretrained)\")\n",
    "        print(f\"  Output features: {in_features}\")\n",
    "        \n",
    "        # Shared neck for feature processing\n",
    "        self.shared_neck = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # === REGRESSION BRANCH (Beauty Score Prediction) ===\n",
    "        # Fully connected layers with dropout, ending in single neuron with linear activation\n",
    "        self.regression_branch = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),  # Prevent overfitting\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 1)  # Single neuron, linear activation (implicit)\n",
    "        )\n",
    "        \n",
    "        # === CLASSIFICATION BRANCH (Emotion Recognition) ===\n",
    "        # Fully connected layers with dropout, ending in 7 neurons with softmax\n",
    "        self.classification_branch = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),  # Prevent overfitting\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, num_emotions)  # 7 neurons for 7 emotion classes\n",
    "        )\n",
    "        \n",
    "        print(f\"✓ Regression Branch: Predicts beauty score [1.0 - 5.0]\")\n",
    "        print(f\"✓ Classification Branch: Classifies 7 emotion categories\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # EfficientNet sudah global avg pooling, output (B, 1280)\n",
    "        features = self.backbone(x)          # (B, 1280)\n",
    "\n",
    "        shared = self.shared_neck(features)  # (B, 512)\n",
    "\n",
    "        beauty_score = self.regression_branch(shared).squeeze(1)  # (B,)\n",
    "        emotion_logits = self.classification_branch(shared)       # (B, 7)\n",
    "\n",
    "        return emotion_logits, beauty_score\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Prediction with explicit softmax for inference\n",
    "        (Thesis mentions softmax activation for probability distribution)\n",
    "        \"\"\"\n",
    "        emotion_logits, beauty_score = self.forward(x)\n",
    "        emotion_probs = torch.softmax(emotion_logits, dim=1)  # Explicit softmax\n",
    "        return emotion_probs, beauty_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c43a0a3-b788-42e9-927f-31be02f5cda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FERDataset(Dataset):\n",
    "    \"\"\"FER-2013 Dataset\"\"\"\n",
    "    def __init__(self, npz_path, split='train', transform=None):\n",
    "        data = np.load(npz_path)\n",
    "        \n",
    "        if split == 'train':\n",
    "            self.images = data['X_train']\n",
    "            self.labels = data['y_train']\n",
    "        else:\n",
    "            self.images = data['X_test']\n",
    "            self.labels = data['y_test']\n",
    "        \n",
    "        self.transform = transform\n",
    "        print(f\"✓ FER-2013 {split}: {len(self.labels)} samples\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = int(self.labels[idx])\n",
    "        img = torch.tensor(img, dtype=torch.float32).permute(2, 0, 1)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "class SCUTDataset(Dataset):\n",
    "    \"\"\"SCUT-FBP5500 Dataset\"\"\"\n",
    "    def __init__(self, npz_path, split='train', transform=None):\n",
    "        data = np.load(npz_path)\n",
    "        \n",
    "        if split == 'train':\n",
    "            self.images = data['X_train']\n",
    "            self.scores = data['y_train']\n",
    "        elif split == 'val':\n",
    "            self.images = data['X_val']\n",
    "            self.scores = data['y_val']\n",
    "        else:\n",
    "            self.images = data['X_test']\n",
    "            self.scores = data['y_test']\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.score_min = 1.0\n",
    "        self.score_max = 5.0\n",
    "        \n",
    "        print(f\"✓ SCUT-FBP5500 {split}: {len(self.scores)} samples\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.scores)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        score = float(self.scores[idx])\n",
    "        score_norm = (score - self.score_min) / (self.score_max - self.score_min)\n",
    "        \n",
    "        img = torch.tensor(img, dtype=torch.float32).permute(2, 0, 1)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, score_norm\n",
    "\n",
    "class CombinedMTLDataset(Dataset):\n",
    "    \"\"\"Combined dataset for MTL - FIXED VERSION\"\"\"\n",
    "    def __init__(self, fer_dataset, scut_dataset, mode='alternate'):\n",
    "        self.fer_dataset = fer_dataset\n",
    "        self.scut_dataset = scut_dataset\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.fer_size = len(fer_dataset)\n",
    "        self.scut_size = len(scut_dataset)\n",
    "        \n",
    "        if mode == 'alternate':\n",
    "            # Create explicit index mapping to avoid duplicates\n",
    "            self.indices = []\n",
    "            fer_idx = 0\n",
    "            scut_idx = 0\n",
    "            \n",
    "            # Alternate between FER and SCUT until both are exhausted\n",
    "            while fer_idx < self.fer_size or scut_idx < self.scut_size:\n",
    "                if fer_idx < self.fer_size:\n",
    "                    self.indices.append(('fer', fer_idx))\n",
    "                    fer_idx += 1\n",
    "                \n",
    "                if scut_idx < self.scut_size:\n",
    "                    self.indices.append(('scut', scut_idx))\n",
    "                    scut_idx += 1\n",
    "            \n",
    "            self.total_size = len(self.indices)\n",
    "        else:\n",
    "            # Simple concatenation\n",
    "            self.total_size = self.fer_size + self.scut_size\n",
    "        \n",
    "        print(f\"\\n✓ Combined MTL Dataset ({mode} mode):\")\n",
    "        print(f\"  FER: {self.fer_size} | SCUT: {self.scut_size} | Total: {self.total_size}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.total_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'alternate':\n",
    "            # Use pre-computed index mapping\n",
    "            source, source_idx = self.indices[idx]\n",
    "            \n",
    "            if source == 'fer':\n",
    "                img, emotion_label = self.fer_dataset[source_idx]\n",
    "                beauty_score = 0.0\n",
    "                has_emotion = True\n",
    "                has_beauty = False\n",
    "            else:  # scut\n",
    "                img, beauty_score = self.scut_dataset[source_idx]\n",
    "                emotion_label = 0\n",
    "                has_emotion = False\n",
    "                has_beauty = True\n",
    "        else:\n",
    "            # Simple concatenation mode\n",
    "            if idx < self.fer_size:\n",
    "                img, emotion_label = self.fer_dataset[idx]\n",
    "                beauty_score = 0.0\n",
    "                has_emotion = True\n",
    "                has_beauty = False\n",
    "            else:\n",
    "                img, beauty_score = self.scut_dataset[idx - self.fer_size]\n",
    "                emotion_label = 0\n",
    "                has_emotion = False\n",
    "                has_beauty = True\n",
    "        \n",
    "        return img, emotion_label, beauty_score, has_emotion, has_beauty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a04c314-e5bb-4a71-8c4e-0e86ab92886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mtl_epoch(model, train_loader, emotion_criterion, beauty_criterion,\n",
    "                   optimizer, device, emotion_weight=1.0, beauty_weight=10.0):\n",
    "    \"\"\"Train one epoch\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    emotion_correct, emotion_total = 0, 0\n",
    "    beauty_errors = []\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=\"Training\")\n",
    "    \n",
    "    for images, emotion_labels, beauty_scores, has_emotion, has_beauty in pbar:\n",
    "        images = images.to(device)\n",
    "        emotion_labels = emotion_labels.to(device)\n",
    "        beauty_scores = beauty_scores.to(device).float()\n",
    "        has_emotion = has_emotion.to(device)\n",
    "        has_beauty = has_beauty.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        emotion_logits, beauty_pred = model(images)\n",
    "        \n",
    "        loss = 0.0\n",
    "        \n",
    "        if has_emotion.sum() > 0:\n",
    "            emotion_loss = emotion_criterion(\n",
    "                emotion_logits[has_emotion],\n",
    "                emotion_labels[has_emotion]\n",
    "            )\n",
    "            loss += emotion_weight * emotion_loss\n",
    "            \n",
    "            _, preds = emotion_logits[has_emotion].max(1)\n",
    "            emotion_correct += preds.eq(emotion_labels[has_emotion]).sum().item()\n",
    "            emotion_total += has_emotion.sum().item()\n",
    "        \n",
    "        if has_beauty.sum() > 0:\n",
    "            beauty_loss = beauty_criterion(\n",
    "                beauty_pred[has_beauty],\n",
    "                beauty_scores[has_beauty]\n",
    "            )\n",
    "            loss += beauty_weight * beauty_loss\n",
    "            \n",
    "            errors = torch.abs(beauty_pred[has_beauty] - beauty_scores[has_beauty])\n",
    "            beauty_errors.extend(errors.detach().cpu().numpy())\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'emo': f'{100.*emotion_correct/max(emotion_total,1):.1f}%',\n",
    "            'beauty': f'{np.mean(beauty_errors):.4f}' if beauty_errors else 'N/A'\n",
    "        })\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_emotion_acc = 100.0 * emotion_correct / max(emotion_total, 1)\n",
    "    train_beauty_mae = np.mean(beauty_errors) if beauty_errors else 0.0\n",
    "    \n",
    "    return avg_loss, train_emotion_acc, train_beauty_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d0d094-29b7-4de9-911f-8ac26b8476a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_mtl(model, fer_loader, scut_loader, device):\n",
    "    \"\"\"Validate on both tasks\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Emotion\n",
    "    emotion_correct, emotion_total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in fer_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            emotion_logits, _ = model(images)\n",
    "            _, preds = emotion_logits.max(1)\n",
    "            emotion_correct += preds.eq(labels).sum().item()\n",
    "            emotion_total += labels.size(0)\n",
    "    \n",
    "    emotion_acc = 100.0 * emotion_correct / emotion_total\n",
    "    \n",
    "    # Beauty\n",
    "    beauty_preds, beauty_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, scores in scut_loader:\n",
    "            images = images.to(device)\n",
    "            _, beauty_pred = model(images)\n",
    "            beauty_preds.extend(beauty_pred.cpu().numpy())\n",
    "            beauty_targets.extend(scores.numpy())\n",
    "    \n",
    "    beauty_mae = mean_absolute_error(beauty_targets, beauty_preds)\n",
    "    beauty_mae_original = beauty_mae * 4.0  # Denormalize\n",
    "    \n",
    "    return emotion_acc, beauty_mae, beauty_mae_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6439bed3-f546-4ee0-8d78-5a71f3cf8227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_efficientnet_mtl(fer_npz, scut_npz, device,\n",
    "                          epochs=50, batch_size=64,\n",
    "                          emotion_weight=1.0, beauty_weight=10.0):\n",
    "    \"\"\"\n",
    "    Complete EfficientNet-B0 MTL training following thesis methodology:\n",
    "    \n",
    "    Transfer Learning Strategy (Thesis Section):\n",
    "    1. Initial Training: Freeze all EfficientNet-B0 layers\n",
    "       - Preserves low-level feature representations from pre-training\n",
    "       - Only train classification and regression branches\n",
    "    \n",
    "    2. Fine-tuning: Gradual unfreezing (epoch 8)\n",
    "       - Progressively unfreeze higher layers\n",
    "       - Allows model to adapt to facial domain\n",
    "    \n",
    "    Optimization (Thesis Section):\n",
    "    - Optimizer: AdamW (adaptive optimizer)\n",
    "    - Learning rate: 2e-3 (optimal for stable convergence)\n",
    "    - Batch size: 64 (balance between stability and memory efficiency)\n",
    "    \n",
    "    Regularization (Thesis Section):\n",
    "    - Early stopping: Monitor validation loss\n",
    "    - Dropout: Prevent overfitting (before output layers)\n",
    "    \n",
    "    Loss Function (Thesis Section):\n",
    "    - Regression: MSE loss (measures difference between prediction and actual)\n",
    "    - Classification: CrossEntropyLoss (measures probability distribution)\n",
    "    - Total Loss: Weighted combination (emotion_weight + beauty_weight)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"EFFICIENTNET-B0 MULTI-TASK LEARNING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load datasets\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=10),\n",
    "    ])\n",
    "    \n",
    "    fer_train = FERDataset(fer_npz, split='train', transform=train_transform)\n",
    "    fer_test = FERDataset(fer_npz, split='test', transform=None)\n",
    "    scut_train = SCUTDataset(scut_npz, split='train', transform=train_transform)\n",
    "    scut_test = SCUTDataset(scut_npz, split='test', transform=None)\n",
    "    \n",
    "    combined_train = CombinedMTLDataset(fer_train, scut_train, mode='alternate')\n",
    "    \n",
    "    train_loader = DataLoader(combined_train, batch_size=batch_size,\n",
    "                             shuffle=True, num_workers=0, pin_memory=True)\n",
    "    fer_test_loader = DataLoader(fer_test, batch_size=batch_size,\n",
    "                                 shuffle=False, num_workers=0)\n",
    "    scut_test_loader = DataLoader(scut_test, batch_size=batch_size,\n",
    "                                  shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Model\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CREATING EFFICIENTNET-B0 MODEL\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    model = EfficientNetMTLModel(num_emotions=7).to(device)\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"✓ Total parameters: {total_params:,}\")\n",
    "    print(f\"✓ Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"  (ResNet-50 has ~25.6M params)\")\n",
    "    print(f\"  EfficientNet-B0 is {(25.6/total_params*1e6):.1f}x smaller! 🚀\")\n",
    "    \n",
    "    # Loss & optimizer\n",
    "    emotion_criterion = nn.CrossEntropyLoss()\n",
    "    beauty_criterion = nn.MSELoss()\n",
    "    \n",
    "    # Freeze backbone initially\n",
    "    for param in model.backbone.parameters():\n",
    "        param.requires_grad = False\n",
    "    print(\"\\n✓ Backbone frozen for initial training\")\n",
    "    \n",
    "    # Optimizer with higher learning rate (EfficientNet can handle it)\n",
    "    optimizer = optim.AdamW([\n",
    "        {'params': model.shared_neck.parameters(), 'lr': 2e-3},\n",
    "        {'params': model.classification_branch.parameters(), 'lr': 2e-3},\n",
    "        {'params': model.regression_branch.parameters(), 'lr': 2e-3},\n",
    "    ], weight_decay=1e-4)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=3\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    best_emotion_acc = 0.0\n",
    "    best_beauty_mae = float('inf')\n",
    "    best_combined_score = -float('inf')\n",
    "    patience_counter = 0\n",
    "    patience = 10\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [], 'train_emotion_acc': [], 'train_beauty_mae': [],\n",
    "        'val_emotion_acc': [], 'val_beauty_mae': []\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STARTING TRAINING\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Loss weights: emotion={emotion_weight}, beauty={beauty_weight}\\n\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_emo_acc, train_beauty_mae = train_mtl_epoch(\n",
    "            model, train_loader, emotion_criterion, beauty_criterion,\n",
    "            optimizer, device, emotion_weight, beauty_weight\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        val_emo_acc, val_beauty_mae, val_beauty_mae_original = validate_mtl(\n",
    "            model, fer_test_loader, scut_test_loader, device\n",
    "        )\n",
    "        \n",
    "        # Store history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_emotion_acc'].append(train_emo_acc)\n",
    "        history['train_beauty_mae'].append(train_beauty_mae)\n",
    "        history['val_emotion_acc'].append(val_emo_acc)\n",
    "        history['val_beauty_mae'].append(val_beauty_mae_original)\n",
    "        \n",
    "        # Print\n",
    "        print(f\"\\nResults:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"  Train Emotion: {train_emo_acc:.2f}%\")\n",
    "        print(f\"  Train Beauty MAE: {train_beauty_mae:.4f}\")\n",
    "        print(f\"  Val Emotion: {val_emo_acc:.2f}%\")\n",
    "        print(f\"  Val Beauty MAE: {val_beauty_mae_original:.4f}\")\n",
    "        \n",
    "        combined_score = (val_emo_acc / 100.0) - (val_beauty_mae_original / 5.0)\n",
    "        \n",
    "        scheduler.step(combined_score)\n",
    "        \n",
    "        # Unfreeze after epoch 8 (earlier than ResNet due to smaller model)\n",
    "        if epoch == 8:\n",
    "            print(\"\\n Unfreezing backbone...\")\n",
    "            for param in model.backbone.parameters():\n",
    "                param.requires_grad = True\n",
    "            optimizer.add_param_group({'params': model.backbone.parameters(), 'lr': 5e-5})\n",
    "        \n",
    "        # Early stopping\n",
    "        if combined_score > best_combined_score:\n",
    "            best_combined_score = combined_score\n",
    "            best_emotion_acc = val_emo_acc\n",
    "            best_beauty_mae = val_beauty_mae_original\n",
    "            patience_counter = 0\n",
    "            \n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'emotion_acc': val_emo_acc,\n",
    "                'beauty_mae': val_beauty_mae_original,\n",
    "                'history': history\n",
    "            }, \"mtl_efficientnet_best.pth\")\n",
    "            \n",
    "            print(f\"\\n✅ New best! Emotion: {val_emo_acc:.2f}%, Beauty: {val_beauty_mae_original:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"\\n No improvement ({patience_counter}/{patience})\")\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                print(f\"\\n Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EFFICIENTNET-B0 TRAINING COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nBest Results:\")\n",
    "    print(f\"  Emotion Accuracy: {best_emotion_acc:.2f}%\")\n",
    "    print(f\"  Beauty MAE: {best_beauty_mae:.4f}\")\n",
    "    print(f\"\\n Comparison to ResNet-50:\")\n",
    "    print(f\"  ResNet-50:\")\n",
    "    print(f\"    Emotion: 64.73% | Beauty MAE: 0.2187 | Params: 25.6M\")\n",
    "    print(f\"  EfficientNet-B0:\")\n",
    "    print(f\"    Emotion: {best_emotion_acc:.2f}% | Beauty MAE: {best_beauty_mae:.4f} | Params: ~5.3M\")\n",
    "    print(f\"\\n  Improvement:\")\n",
    "    print(f\"    Emotion: {best_emotion_acc-64.73:+.2f}%\")\n",
    "    print(f\"    Beauty MAE: {best_beauty_mae-0.2187:+.4f}\")\n",
    "    print(f\"    Parameters: -79% smaller! \")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a643d46-88fb-456a-893a-5a01c2c4e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Paths\n",
    "    FER_data = \"fer2013_processed_final.npz\"\n",
    "    SCUT_data = \"scutfbp5500_processed_final.npz\"\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\\n\")\n",
    "    \n",
    "    # Train\n",
    "    history, model = train_efficientnet_mtl(\n",
    "        fer_npz=FER_data,\n",
    "        scut_npz=SCUT_data,\n",
    "        device=device,\n",
    "        epochs=50,\n",
    "        batch_size=64,\n",
    "        emotion_weight=1.0,\n",
    "        beauty_weight=10.0\n",
    "    )\n",
    "    \n",
    "    print(\"\\n✓ Model saved as: mtl_efficientnet_best.pth\")\n",
    "    print(\"✓ Ready for evaluation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e9d3c1-0c24-45e3-9fbd-27739d8bca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetMTLModel(nn.Module):\n",
    "    \"\"\"Same architecture as training\"\"\"\n",
    "    def __init__(self, num_emotions=7):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone = models.efficientnet_b0(pretrained=True)\n",
    "        in_features = self.backbone.classifier[1].in_features\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "    \n",
    "        self.shared_neck = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.regression_branch = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "        self.classification_branch = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, num_emotions)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        shared = self.shared_neck(features)\n",
    "        \n",
    "        beauty_score = self.regression_branch(shared).squeeze(1)\n",
    "        emotion_logits = self.classification_branch(shared)\n",
    "        \n",
    "        return emotion_logits, beauty_score\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"Prediction with explicit softmax\"\"\"\n",
    "        emotion_logits, beauty_score = self.forward(x)\n",
    "        emotion_probs = torch.softmax(emotion_logits, dim=1)\n",
    "        return emotion_probs, beauty_score\n",
    "\n",
    "def load_model(checkpoint_path, device):\n",
    "    \"\"\"Load trained EfficientNet MTL model\"\"\"\n",
    "    model = EfficientNetMTLModel(num_emotions=7).to(device)\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"✓ Loaded EfficientNet-B0 MTL model from epoch {checkpoint['epoch']+1}\")\n",
    "    print(f\"✓ Best Emotion Acc: {checkpoint['emotion_acc']:.2f}%\")\n",
    "    print(f\"✓ Best Beauty MAE: {checkpoint['beauty_mae']:.4f}\")\n",
    "    \n",
    "    return model, checkpoint\n",
    "\n",
    "\n",
    "class FERDataset:\n",
    "    \"\"\"FER-2013 Dataset\"\"\"\n",
    "    def __init__(self, npz_path, split='test'):\n",
    "        data = np.load(npz_path)\n",
    "        self.images = data['X_test']\n",
    "        self.labels = data['y_test']\n",
    "        print(f\"✓ FER-2013 {split}: {len(self.labels)} samples\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = int(self.labels[idx])\n",
    "        img = torch.tensor(img, dtype=torch.float32).permute(2, 0, 1)\n",
    "        return img, label\n",
    "\n",
    "class SCUTDataset:\n",
    "    \"\"\"SCUT-FBP5500 Dataset\"\"\"\n",
    "    def __init__(self, npz_path, split='test'):\n",
    "        data = np.load(npz_path)\n",
    "        self.images = data['X_test']\n",
    "        self.scores = data['y_test']\n",
    "        print(f\"✓ SCUT-FBP5500 {split}: {len(self.scores)} samples\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.scores)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        score = float(self.scores[idx])\n",
    "        score_norm = (score - 1.0) / 4.0\n",
    "        img = torch.tensor(img, dtype=torch.float32).permute(2, 0, 1)\n",
    "        return img, score_norm\n",
    "\n",
    "\n",
    "def evaluate_emotion(model, test_loader, device):\n",
    "    \"\"\"Evaluate emotion classification\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            emotion_logits, _ = model(images)\n",
    "            \n",
    "            probs = torch.softmax(emotion_logits, dim=1)\n",
    "            _, preds = emotion_logits.max(1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return all_preds, all_labels, all_probs, accuracy\n",
    "\n",
    "def evaluate_beauty(model, test_loader, device):\n",
    "    \"\"\"Evaluate beauty regression\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, scores in test_loader:\n",
    "            images = images.to(device)\n",
    "            _, beauty_pred = model(images)\n",
    "            \n",
    "            # Denormalize to [1, 5]\n",
    "            beauty_pred_original = beauty_pred.cpu().numpy() * 4.0 + 1.0\n",
    "            scores_original = scores.numpy() * 4.0 + 1.0\n",
    "            \n",
    "            all_preds.extend(beauty_pred_original)\n",
    "            all_targets.extend(scores_original)\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_targets = np.array(all_targets)\n",
    "    \n",
    "    mae = mean_absolute_error(all_targets, all_preds)\n",
    "    rmse = np.sqrt(np.mean((all_targets - all_preds) ** 2))\n",
    "    correlation, _ = pearsonr(all_targets, all_preds)\n",
    "    \n",
    "    return all_preds, all_targets, mae, rmse, correlation\n",
    "\n",
    "\n",
    "def plot_emotion_confusion_matrix(labels, preds, save_path='efficientnet_emotion_cm.png'):\n",
    "    \"\"\"Plot confusion matrix for emotion\"\"\"\n",
    "    emotion_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "    \n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Counts\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=emotion_names, yticklabels=emotion_names,\n",
    "                cbar_kws={'label': 'Count'}, ax=axes[0])\n",
    "    axes[0].set_xlabel('Predicted Emotion', fontsize=12)\n",
    "    axes[0].set_ylabel('True Emotion', fontsize=12)\n",
    "    axes[0].set_title(f'EfficientNet-B0 Confusion Matrix (Counts)\\nAccuracy: {accuracy:.2%}', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Percentages\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
    "                xticklabels=emotion_names, yticklabels=emotion_names,\n",
    "                cbar_kws={'label': 'Percentage'}, ax=axes[1])\n",
    "    axes[1].set_xlabel('Predicted Emotion', fontsize=12)\n",
    "    axes[1].set_ylabel('True Emotion', fontsize=12)\n",
    "    axes[1].set_title('Normalized Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ Saved: {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_beauty_results(targets, preds, mae, rmse, corr, save_path='efficientnet_beauty_results.png'):\n",
    "    \"\"\"Plot beauty regression results\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Scatter plot\n",
    "    axes[0].scatter(targets, preds, alpha=0.5, s=30, edgecolors='black', linewidth=0.5)\n",
    "    axes[0].plot([1, 5], [1, 5], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "    axes[0].set_xlabel('True Beauty Score', fontsize=12)\n",
    "    axes[0].set_ylabel('Predicted Score', fontsize=12)\n",
    "    axes[0].set_title(f'EfficientNet-B0 Beauty Predictions\\nMAE: {mae:.4f} | Corr: {corr:.4f}',\n",
    "                     fontsize=13, fontweight='bold')\n",
    "    axes[0].legend(fontsize=10)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].set_xlim(0.5, 5.5)\n",
    "    axes[0].set_ylim(0.5, 5.5)\n",
    "    \n",
    "    # Error distribution\n",
    "    errors = preds - targets\n",
    "    axes[1].hist(errors, bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    axes[1].axvline(0, color='red', linestyle='--', linewidth=2, label='Zero Error')\n",
    "    axes[1].set_xlabel('Prediction Error', fontsize=12)\n",
    "    axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[1].set_title(f'Error Distribution\\nMean: {errors.mean():.4f} | Std: {errors.std():.4f}',\n",
    "                     fontsize=13, fontweight='bold')\n",
    "    axes[1].legend(fontsize=10)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Residual plot\n",
    "    axes[2].scatter(targets, errors, alpha=0.5, s=30, edgecolors='black', linewidth=0.5)\n",
    "    axes[2].axhline(0, color='red', linestyle='--', linewidth=2)\n",
    "    axes[2].set_xlabel('True Score', fontsize=12)\n",
    "    axes[2].set_ylabel('Residual', fontsize=12)\n",
    "    axes[2].set_title('Residual Plot', fontsize=13, fontweight='bold')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ Saved: {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_per_class_accuracy(labels, preds, save_path='efficientnet_per_class_acc.png'):\n",
    "    \"\"\"Plot per-class emotion accuracy\"\"\"\n",
    "    emotion_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "    \n",
    "    class_accs = []\n",
    "    class_counts = []\n",
    "    \n",
    "    for i in range(7):\n",
    "        mask = labels == i\n",
    "        if mask.sum() > 0:\n",
    "            acc = accuracy_score(labels[mask], preds[mask])\n",
    "            class_accs.append(acc * 100)\n",
    "            class_counts.append(mask.sum())\n",
    "        else:\n",
    "            class_accs.append(0)\n",
    "            class_counts.append(0)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    x = np.arange(len(emotion_names))\n",
    "    bars = ax.bar(x, class_accs, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    \n",
    "    # Add labels\n",
    "    for i, (bar, count) in enumerate(zip(bars, class_counts)):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{height:.1f}%\\n(n={count})',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    ax.set_xlabel('Emotion Class', fontsize=12)\n",
    "    ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    ax.set_title('EfficientNet-B0 Per-Class Emotion Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(emotion_names, rotation=45, ha='right')\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ Saved: {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "def visualize_sample_predictions(model, fer_dataset, scut_dataset, device,\n",
    "                                n_samples=8, save_path='efficientnet_samples.png'):\n",
    "    \"\"\"Visualize sample predictions\"\"\"\n",
    "    model.eval()\n",
    "    emotion_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, n_samples, figsize=(3*n_samples, 7))\n",
    "    \n",
    "    # FER samples\n",
    "    fer_indices = random.sample(range(len(fer_dataset)), n_samples)\n",
    "    for i, idx in enumerate(fer_indices):\n",
    "        img_tensor, true_label = fer_dataset[idx]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            img_batch = img_tensor.unsqueeze(0).to(device)\n",
    "            emotion_logits, beauty_pred = model(img_batch)\n",
    "            probs = torch.softmax(emotion_logits, dim=1)\n",
    "            pred_label = emotion_logits.argmax(dim=1).item()\n",
    "            confidence = probs[0, pred_label].item()\n",
    "            beauty_score = beauty_pred.item() * 4.0 + 1.0\n",
    "        \n",
    "        img_display = img_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "        img_display = np.clip(img_display, 0, 1)\n",
    "        \n",
    "        axes[0, i].imshow(img_display)\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        color = 'green' if pred_label == true_label else 'red'\n",
    "        axes[0, i].set_title(\n",
    "            f\"True: {emotion_names[true_label]}\\n\"\n",
    "            f\"Pred: {emotion_names[pred_label]}\\n\"\n",
    "            f\"Conf: {confidence:.2%}\\n\"\n",
    "            f\"Beauty: {beauty_score:.2f}\",\n",
    "            fontsize=9, color=color, fontweight='bold'\n",
    "        )\n",
    "    \n",
    "    # SCUT samples\n",
    "    scut_indices = random.sample(range(len(scut_dataset)), n_samples)\n",
    "    for i, idx in enumerate(scut_indices):\n",
    "        img_tensor, true_score_norm = scut_dataset[idx]\n",
    "        true_score = true_score_norm * 4.0 + 1.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            img_batch = img_tensor.unsqueeze(0).to(device)\n",
    "            emotion_logits, beauty_pred = model(img_batch)\n",
    "            probs = torch.softmax(emotion_logits, dim=1)\n",
    "            pred_emotion = emotion_logits.argmax(dim=1).item()\n",
    "            emotion_conf = probs[0, pred_emotion].item()\n",
    "            pred_score = beauty_pred.item() * 4.0 + 1.0\n",
    "        \n",
    "        img_display = img_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "        img_display = np.clip(img_display, 0, 1)\n",
    "        \n",
    "        axes[1, i].imshow(img_display)\n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "        error = abs(pred_score - true_score)\n",
    "        color = 'green' if error < 0.3 else 'orange' if error < 0.6 else 'red'\n",
    "        axes[1, i].set_title(\n",
    "            f\"True: {true_score:.2f}\\n\"\n",
    "            f\"Pred: {pred_score:.2f}\\n\"\n",
    "            f\"Error: {error:.2f}\\n\"\n",
    "            f\"Emotion: {emotion_names[pred_emotion]}\",\n",
    "            fontsize=9, color=color, fontweight='bold'\n",
    "        )\n",
    "    \n",
    "    fig.text(0.01, 0.75, 'FER-2013\\n(Emotion)', \n",
    "             fontsize=14, fontweight='bold', rotation=90, va='center')\n",
    "    fig.text(0.01, 0.25, 'SCUT-FBP5500\\n(Beauty)', \n",
    "             fontsize=14, fontweight='bold', rotation=90, va='center')\n",
    "    \n",
    "    plt.suptitle('EfficientNet-B0 Sample Predictions', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout(rect=[0.03, 0, 1, 0.97])\n",
    "    plt.savefig(save_path, dpi=200, bbox_inches='tight')\n",
    "    print(f\"✓ Saved: {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def evaluate_efficientnet_mtl(checkpoint_path, fer_npz, scut_npz, device):\n",
    "    \"\"\"Complete evaluation pipeline\"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"EFFICIENTNET-B0 MTL MODEL EVALUATION\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Load model\n",
    "    model, checkpoint = load_model(checkpoint_path, device)\n",
    "    \n",
    "    # Load datasets\n",
    "    print(\"\\n📂 Loading test datasets...\")\n",
    "    fer_test = FERDataset(fer_npz, split='test')\n",
    "    scut_test = SCUTDataset(scut_npz, split='test')\n",
    "    \n",
    "    fer_test_loader = DataLoader(fer_test, batch_size=64, shuffle=False, num_workers=0)\n",
    "    scut_test_loader = DataLoader(scut_test, batch_size=64, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Evaluate emotion\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EVALUATING EMOTION CLASSIFICATION\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    emotion_preds, emotion_labels, emotion_probs, emotion_acc = evaluate_emotion(\n",
    "        model, fer_test_loader, device\n",
    "    )\n",
    "    \n",
    "    print(f\"Emotion Accuracy: {emotion_acc:.2%} ({emotion_acc*100:.2f}%)\")\n",
    "    \n",
    "    emotion_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(emotion_labels, emotion_preds, target_names=emotion_names))\n",
    "    \n",
    "    print(\"\\nPer-Class Accuracy:\")\n",
    "    for i, name in enumerate(emotion_names):\n",
    "        mask = emotion_labels == i\n",
    "        if mask.sum() > 0:\n",
    "            acc = accuracy_score(emotion_labels[mask], emotion_preds[mask])\n",
    "            print(f\"  {name:12s}: {acc:.2%} ({mask.sum()} samples)\")\n",
    "    \n",
    "    # Evaluate beauty\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EVALUATING BEAUTY REGRESSION\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    beauty_preds, beauty_targets, beauty_mae, beauty_rmse, beauty_corr = evaluate_beauty(\n",
    "        model, scut_test_loader, device\n",
    "    )\n",
    "    \n",
    "    print(f\"Beauty MAE:  {beauty_mae:.4f}\")\n",
    "    print(f\"Beauty RMSE: {beauty_rmse:.4f}\")\n",
    "    print(f\"Pearson Correlation: {beauty_corr:.4f}\")\n",
    "    \n",
    "    # Generate visualizations\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"GENERATING VISUALIZATIONS\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    plot_emotion_confusion_matrix(emotion_labels, emotion_preds)\n",
    "    plot_per_class_accuracy(emotion_labels, emotion_preds)\n",
    "    plot_beauty_results(beauty_targets, beauty_preds, beauty_mae, beauty_rmse, beauty_corr)\n",
    "    visualize_sample_predictions(model, fer_test, scut_test, device)\n",
    "    \n",
    "    # Final summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FINAL RESULTS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n Emotion Classification:\")\n",
    "    print(f\"   Test Accuracy: {emotion_acc:.2%}\")\n",
    "    print(f\"\\n Beauty Regression:\")\n",
    "    print(f\"   Test MAE: {beauty_mae:.4f}\")\n",
    "    print(f\"   Test RMSE: {beauty_rmse:.4f}\")\n",
    "    print(f\"   Correlation: {beauty_corr:.4f}\")\n",
    "    print(f\"\\n Generated Files:\")\n",
    "    print(f\"   - efficientnet_emotion_cm.png\")\n",
    "    print(f\"   - efficientnet_per_class_acc.png\")\n",
    "    print(f\"   - efficientnet_beauty_results.png\")\n",
    "    print(f\"   - efficientnet_samples.png\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return {\n",
    "        'emotion_acc': emotion_acc,\n",
    "        'beauty_mae': beauty_mae,\n",
    "        'beauty_rmse': beauty_rmse,\n",
    "        'beauty_corr': beauty_corr\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths\n",
    "    checkpoint_path = \"mtl_efficientnet_best.pth\"\n",
    "    fer_npz = \"fer2013_processed_final.npz\"\n",
    "    scut_npz = \"scutfbp5500_processed_final.npz\"\n",
    "    \n",
    "    # Device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\\n\")\n",
    "    \n",
    "    # Run evaluation\n",
    "    results = evaluate_efficientnet_mtl(checkpoint_path, fer_npz, scut_npz, device)\n",
    "    \n",
    "    print(\"\\n✓ Evaluation complete!\")\n",
    "    print(f\"\\nQuick Summary:\")\n",
    "    print(f\"  Emotion: {results['emotion_acc']*100:.2f}%\")\n",
    "    print(f\"  Beauty MAE: {results['beauty_mae']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88dc1095-4b4d-46bb-bab9-12a21689408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7c42c07-7ba2-4786-94ce-06a0f95bd55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache_resource\n",
    "def load_models():\n",
    "    \"\"\"Load both models\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    models_dict = {\n",
    "        'beauty': None,\n",
    "        'mtl': None\n",
    "    }\n",
    "    \n",
    "    # Load Beauty Regression Model\n",
    "    try:\n",
    "        beauty_model = BeautyRegressionModel()\n",
    "        checkpoint = torch.load('best_efficientnet_scut_model.pth', \n",
    "                          map_location=device, weights_only=False)  # Changed to False\n",
    "    \n",
    "        # Load the model state dict properly\n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            beauty_model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "        else:\n",
    "            beauty_model.load_state_dict(checkpoint, strict=True)\n",
    "    \n",
    "        beauty_model.to(device)\n",
    "        beauty_model.eval()\n",
    "        models_dict['beauty'] = beauty_model\n",
    "        st.success(\"✅ Beauty regression model loaded successfully\")\n",
    "    except FileNotFoundError:\n",
    "        st.warning(\"⚠️ Beauty regression model file not found: 'best_efficientnet_scut_model.pth'\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"❌ Error loading beauty model: {str(e)[:200]}\")\n",
    "    \n",
    "    # Load Multi-Task Learning Model\n",
    "    try:\n",
    "        mtl_model = EfficientNetMTLModel(num_emotions=7)\n",
    "        checkpoint = torch.load('mtl_efficientnet_best.pth', \n",
    "                              map_location=device, weights_only=False)  # Changed to False\n",
    "        mtl_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        mtl_model.to(device)\n",
    "        mtl_model.eval()\n",
    "        models_dict['mtl'] = mtl_model\n",
    "        st.success(\"✅ Multi-task model loaded successfully\")\n",
    "    except FileNotFoundError:\n",
    "        st.warning(\"⚠️ Multi-task model file not found: 'mtl_efficientnet_best.pth'\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"❌ Error loading MTL model: {str(e)[:200]}\")\n",
    "    \n",
    "    return models_dict, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03f23516-5e7a-483e-bb0a-b21f7ffd9ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in model_state_dict:\n",
      "  features.0.0.weight\n",
      "  features.0.1.weight\n",
      "  features.0.1.bias\n",
      "  features.0.1.running_mean\n",
      "  features.0.1.running_var\n",
      "  features.0.1.num_batches_tracked\n",
      "  features.1.0.block.0.0.weight\n",
      "  features.1.0.block.0.1.weight\n",
      "  features.1.0.block.0.1.bias\n",
      "  features.1.0.block.0.1.running_mean\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('best_efficientnet_scut_model.pth', \n",
    "                       map_location='cpu', weights_only=False)\n",
    "\n",
    "print(\"Keys in model_state_dict:\")\n",
    "for key in list(checkpoint['model_state_dict'].keys())[:10]:\n",
    "    print(f\"  {key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de56657-0c28-43b6-a4ba-5e22a3e198fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfmac)",
   "language": "python",
   "name": "tfmac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
